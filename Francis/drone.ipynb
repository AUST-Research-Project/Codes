{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import XMLParser,ParseError\n",
    "\n",
    "# Root directory of the MASK-RCNN MODEL\n",
    "ROOT_DIR = os.path.abspath(\"C:\\Users\\HP USER\\Documents\\Drone Datasets\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting neccessary directories\n",
    "dir_name= os.fspath('C:\\\\Users\\\\HP USER\\\\Documents\\\\Drone Datasets\\\\semantic_drone_dataset\\\\training_set')\n",
    "image_dir=os.path.join(dir_name,'images')\n",
    "annotations=os.path.join(dir_name,'gt\\\\semantic\\\\label_me_xml')\n",
    "bounding_box=os.path.join(dir_name,'gt\\bounding_box\\label_me_xml')\n",
    "mask_dir=os.path.join(dir_name,'gt\\\\semantic\\\\label_images')\n",
    "class_rgb=os.path.join(dir_name,'gt\\\\semantic\\\\class_dict.csv')\n",
    "tree= os.path.join(annotations,'004.xml')\n",
    "#Reading the files\n",
    "class_rgb = pd.read_csv(class_rgb,delimiter=',') #The class and RGB values for the masks in the final output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DroneConfig(Config):\n",
    "    \"\"\"Configuration for training on the drone  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    \n",
    "    NAME = \"drone\"\n",
    "\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 22  # Background + others\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "class DroneInferenceConfig(DroneConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    RPN_NMS_THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tryig to create the imageids from the xml files, not adviced.\n",
    "def read_xml():\n",
    "    parser = ET.XMLParser(encoding=\"iso-8859-5\") # Parser for XML\n",
    "    #The XML file handling\n",
    "    tree = ET.parse(tree)\n",
    "    root = tree.getroot()\n",
    "    child_tag=[]\n",
    "    image_ids=[]\n",
    "    for child in root:\n",
    "        child_tag.append((child.tag, child.attrib))\n",
    "    elem_tag=[elem.tag for elem in root.iter()]\n",
    "    xml_string=ET.tostring(root, encoding='utf8').decode('utf8')\n",
    "    #print(xml_string)\n",
    "    #SI_attrib=[sourceImage.attrib for sourceImage in root.iter(\"sourceImage\")]\n",
    "    #SI_text=[sourceImage.text for sourceImage in root.iter(\"sourceImage\")]\n",
    "    #Fname_text=[filename.text for filename in root.iter(\"filename\")]\n",
    "    for item in [\"%03d\" % i for i in range(1,599)]: # Creating 3-digits figures to suit the xml file naming\n",
    "        try:\n",
    "            tree= os.path.join(annotations,str(item)+'.xml')\n",
    "            tree = ET.parse(tree)\n",
    "            root = tree.getroot()\n",
    "            file_name_text=[filename.text for filename in root.iter(\"filename\")]\n",
    "            file_name_text=\", \".join(map(str, file_name_text))  #Removing the bracket before appending to image_ids\n",
    "            image_ids.append(file_name_text)\n",
    "        except (FileNotFoundError,ParseError):\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DroneDataset(utils.Dataset):\n",
    "    def load_drone(self, dataset_dir, subset):\n",
    "        class_name=class_rgb['name'].tolist()\n",
    "        for i,classes in enumerate(class_name[1:23],1):\n",
    "            self.add_class(\"semantic\", i, \"classes\")\n",
    "        \n",
    "        #Which subset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "        # Get image ids from directory names        \n",
    "        image_ids = next(os.walk(dataset_dir))[2]\n",
    "        if subset == \"val\":\n",
    "            image_ids= list(set(image_ids[350:]))\n",
    "        else:\n",
    "            if subset == \"train\":\n",
    "                image_ids = list(set(image_ids) - set(image_ids[350:]))\n",
    "\n",
    "        # Add images\n",
    "        for image_id in image_ids:\n",
    "            self.add_image(\n",
    "                \"semantic\",\n",
    "                image_id=image_id,\n",
    "                path=os.path.join(dataset_dir, image_id, \"images/{}.jpg\".format(image_id)))\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        # Get mask directory from image path\n",
    "        mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"masks\")\n",
    "        # Read mask files from .png image\n",
    "        mask = []\n",
    "        for f in next(os.walk(mask_dir))[2]:\n",
    "            if f.endswith(\".png\"):\n",
    "                m = skimage.io.imread(os.path.join(mask_dir, f)).astype(np.bool)\n",
    "                mask.append(m)\n",
    "                \n",
    "        mask = np.stack(mask, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset_dir, subset):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = DroneDataset()\n",
    "    dataset_train.load_drone(dataset_dir, subset)\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = DroneDataset()\n",
    "    dataset_val.load_drone(dataset_dir, \"val\")\n",
    "    dataset_val.prepare()\n",
    "    \n",
    "    #Training the head layer i.e. the early layers of the network \n",
    "    print(\"Train network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=20,\n",
    "                layers='heads')\n",
    "    \n",
    "    # Training all the network\n",
    "    print(\"Train all layers\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=40,\n",
    "                layers='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Since our mask are images in png file format we need to encode them so that we can be able to use them. \n",
    "We will do using the Run Length Encoding (RLE).Run-length encoding (RLE) is a simple form of data compression,\n",
    "where runs (consecutive data elements) are replaced by just one data value and count.\n",
    "\"\"\"\n",
    "def rle_encode(mask):\n",
    "    \"\"\"Encodes a mask in Run Length Encoding (RLE).\n",
    "    Returns a string of space-separated values.\n",
    "    \"\"\"\n",
    "    assert mask.ndim == 2, \"Mask must be of shape [Height, Width]\"\n",
    "    # Flatten it column wise\n",
    "    m = mask.T.flatten()\n",
    "    # Compute gradient. Equals 1 or -1 at transition points\n",
    "    g = np.diff(np.concatenate([[0], m, [0]]), n=1)\n",
    "    # 1-based indicies of transition points (where gradient != 0)\n",
    "    rle = np.where(g != 0)[0].reshape([-1, 2]) + 1\n",
    "    # Convert second index in each pair to lenth\n",
    "    rle[:, 1] = rle[:, 1] - rle[:, 0]\n",
    "    return \" \".join(map(str, rle.flatten()))\n",
    "\n",
    "\n",
    "def rle_decode(rle, shape):\n",
    "    \"\"\"Decodes an RLE encoded list of space separated\n",
    "    numbers and returns a binary mask.\"\"\"\n",
    "    rle = list(map(int, rle.split()))\n",
    "    rle = np.array(rle, dtype=np.int32).reshape([-1, 2])\n",
    "    rle[:, 1] += rle[:, 0]\n",
    "    rle -= 1\n",
    "    mask = np.zeros([shape[0] * shape[1]], np.bool)\n",
    "    for s, e in rle:\n",
    "        assert 0 <= s < mask.shape[0]\n",
    "        assert 1 <= e <= mask.shape[0], \"shape: {}  s {}  e {}\".format(shape, s, e)\n",
    "        mask[s:e] = 1\n",
    "    # Reshape and transpose\n",
    "    mask = mask.reshape([shape[1], shape[0]]).T\n",
    "    return mask\n",
    "\n",
    "\n",
    "def mask_to_rle(image_id, mask, scores):\n",
    "    \"Encodes instance masks to submission format.\"\n",
    "    assert mask.ndim == 3, \"Mask must be [H, W, count]\"\n",
    "    # If mask is empty, return line with image ID only\n",
    "    if mask.shape[-1] == 0:\n",
    "        return \"{},\".format(image_id)\n",
    "    # Remove mask overlaps\n",
    "    # Multiply each instance mask by its score order\n",
    "    # then take the maximum across the last dimension\n",
    "    order = np.argsort(scores)[::-1] + 1  # 1-based descending\n",
    "    mask = np.max(mask * np.reshape(order, [1, 1, -1]), -1)\n",
    "    # Loop over instance masks\n",
    "    lines = []\n",
    "    for o in order:\n",
    "        m = np.where(mask == o, 1, 0)\n",
    "        # Skip if empty\n",
    "        if m.sum() == 0.0:\n",
    "            continue\n",
    "        rle = rle_encode(m)\n",
    "        lines.append(\"{}, {}\".format(image_id, rle))\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(model, dataset_dir, subset):\n",
    "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
    "    print(\"Running on {}\".format(dataset_dir))\n",
    "\n",
    "    # Create directory\n",
    "    if not os.path.exists(RESULTS_DIR):\n",
    "        os.makedirs(RESULTS_DIR)\n",
    "    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
    "    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\n",
    "    os.makedirs(submit_dir)\n",
    "\n",
    "    # Read dataset\n",
    "    dataset = DroneDataset()\n",
    "    dataset.load_drone(dataset_dir, subset) #ATTENTION\n",
    "    dataset.prepare()\n",
    "    # Load over images\n",
    "    submission = []\n",
    "    for image_id in dataset.image_ids:\n",
    "        # Load image and run detection\n",
    "        image = dataset.load_image(image_id)\n",
    "        # Detect objects\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        # Encode image to RLE. Returns a string of multiple lines\n",
    "        source_id = dataset.image_info[image_id][\"id\"]\n",
    "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
    "        submission.append(rle)\n",
    "        # Save image with masks\n",
    "        visualize.display_instances(\n",
    "            image, r['rois'], r['masks'], r['class_ids'],\n",
    "            dataset.class_names, r['scores'],\n",
    "            show_bbox=False, show_mask=False,\n",
    "            title=\"Predictions\")\n",
    "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n",
    "\n",
    "    # Save to csv file\n",
    "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
    "    file_path = os.path.join(submit_dir, \"submit.csv\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(submission)\n",
    "    print(\"Saved to \", submit_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    # Parse command line arguments\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Mask R-CNN for nuclei counting and segmentation')\n",
    "    parser.add_argument(\"command\",\n",
    "                        metavar=\"<command>\",\n",
    "                        help=\"'train' or 'detect'\")\n",
    "    parser.add_argument('--dataset', required=False,\n",
    "                        metavar=\"image_dir\",\n",
    "                        help='Root directory of the dataset')\n",
    "    parser.add_argument('--weights', required=True,\n",
    "                        metavar=\"COCO_WEIGHTS_PATH\",\n",
    "                        help=\"Path to weights .h5 file or 'coco'\")\n",
    "    parser.add_argument('--logs', required=False,\n",
    "                        default=DEFAULT_LOGS_DIR,\n",
    "                        metavar=\"/ROOT_DIR/logs/\",\n",
    "                        help='Logs and checkpoints directory (default=logs/)')\n",
    "    parser.add_argument('--subset', required=False,\n",
    "                        metavar=\"Dataset sub-directory\", #ATTENTION\n",
    "                        help=\"Subset of dataset to run prediction on\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Validate arguments\n",
    "    if args.command == \"train\":\n",
    "        assert args.dataset, \"Argument --dataset is required for training\"\n",
    "    elif args.command == \"detect\":\n",
    "        assert args.subset, \"Provide --subset to run prediction on\"\n",
    "\n",
    "    print(\"Weights: \", args.weights)\n",
    "    print(\"Dataset: \", args.dataset)\n",
    "    if args.subset:\n",
    "        print(\"Subset: \", args.subset)\n",
    "    print(\"Logs: \", args.logs)\n",
    "\n",
    "    # Configurations\n",
    "    if args.command == \"train\":\n",
    "        config = DroneConfig()\n",
    "    else:\n",
    "        config = DroneInferenceConfig()\n",
    "    config.display()\n",
    "\n",
    "    # Create model\n",
    "    if args.command == \"train\":\n",
    "        model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "    else:\n",
    "        model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "\n",
    "    # Select weights file to load\n",
    "    if args.weights.lower() == \"coco\":\n",
    "        weights_path = COCO_WEIGHTS_PATH\n",
    "        # Download weights file\n",
    "        if not os.path.exists(weights_path):\n",
    "            utils.download_trained_weights(weights_path)\n",
    "    elif args.weights.lower() == \"last\":\n",
    "        # Find last trained weights\n",
    "        weights_path = model.find_last()\n",
    "    elif args.weights.lower() == \"imagenet\":\n",
    "        # Start from ImageNet trained weights\n",
    "        weights_path = model.get_imagenet_weights()\n",
    "    else:\n",
    "        weights_path = args.weights\n",
    "\n",
    "    # Load weights\n",
    "    print(\"Loading weights \", weights_path)\n",
    "    if args.weights.lower() == \"coco\":\n",
    "        # Exclude the last layers because they require a matching\n",
    "        # number of classes\n",
    "        model.load_weights(weights_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    else:\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    # Train or evaluate\n",
    "    if args.command == \"train\":\n",
    "        train(model, args.dataset, args.subset)\n",
    "    elif args.command == \"detect\":\n",
    "        detect(model, args.dataset, args.subset)\n",
    "    else:\n",
    "        print(\"'{}' is not recognized. \"\n",
    "              \"Use 'train' or 'detect'\".format(args.command))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
